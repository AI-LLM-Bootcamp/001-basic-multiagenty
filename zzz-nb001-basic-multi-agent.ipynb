{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8205576-b152-4c87-ae66-4298b63fecf6",
   "metadata": {},
   "source": [
    "# LangGraph: Basic Multi-Agent App to replace a Content Marketing Team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1430db7f-5f06-4f40-9e38-6e9694910182",
   "metadata": {},
   "source": [
    "## Why use LangGraph?\n",
    "* To build Multi-Agent LLM Apps.\n",
    "* LangGraph can coordinate multiple agents.\n",
    "* The LLM Apps of the future: Agentic Behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a1fd43-93da-40b2-a778-c787463d5301",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a249d9a-3e16-4244-8a95-9f85a48f89d5",
   "metadata": {},
   "source": [
    "#### After you download the code from the github repository in your computer\n",
    "In terminal:\n",
    "* cd project_name\n",
    "* pyenv local 3.11.4\n",
    "* poetry install\n",
    "* poetry shell\n",
    "\n",
    "#### To open the notebook with Jupyter Notebooks\n",
    "In terminal:\n",
    "* jupyter lab\n",
    "\n",
    "Go to the folder of notebooks and open the right notebook.\n",
    "\n",
    "#### To see the code in Virtual Studio Code or your editor of choice.\n",
    "* open Virtual Studio Code or your editor of choice.\n",
    "* open the project-folder\n",
    "* open the 001-basic-multiagent.py file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac72bb0-1827-48fc-a2c6-69c6d79fc3ef",
   "metadata": {},
   "source": [
    "## Create your .env file\n",
    "* In the github repo we have included a file named .env.example\n",
    "* Rename that file to .env file and here is where you will add your confidential api keys. Remember to include:\n",
    "* OPENAI_API_KEY=your_openai_api_key\n",
    "* LANGCHAIN_TRACING_V2=true\n",
    "* LANGCHAIN_ENDPOINT=https://api.smith.langchain.com\n",
    "* LANGCHAIN_API_KEY=your_langchain_api_key\n",
    "* LANGCHAIN_PROJECT=your_project_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba72a83-fd63-4089-9177-c87b9748aab8",
   "metadata": {},
   "source": [
    "We will call our LangSmith project **182-basic-multimodal**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a25fb-2a73-43d9-b602-2859382b6679",
   "metadata": {},
   "source": [
    "## Connect with the .env file located in the same directory of this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ec7c1b-f292-4f07-a71b-687b4c4d8e79",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "449f690e-a52c-4fa2-8d29-9773f192081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5e029dc7-9395-455a-b8ca-75cb27005ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3157e9a-936c-48b1-8ac2-3698c0827df2",
   "metadata": {},
   "source": [
    "#### Install LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c050e987-7b0d-402a-b5ec-556a467e81cc",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "389d34d4-69e2-4778-9bbc-0a3939629bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "719e66ad-1dec-4f0d-9598-3e97d571d3a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-community"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1175cdf0-5b72-465d-b5b7-8b3b2fd2a54d",
   "metadata": {},
   "source": [
    "## Connect with an LLM and start a conversation with it"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971571d1-ea2e-41d2-b13b-e73f629a5779",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following package because it is already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f056923-4173-4a4b-9266-e561be27b240",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain-openai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893973c7-f27d-4362-b201-be994a8d8f6a",
   "metadata": {},
   "source": [
    "* For this project, **we will use OpenAI's gpt-4-turbo-preview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98c35f17-4cf1-4bbf-97b1-b793b437c682",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8fe5f1-1acd-49ba-bdd8-45ce2af4c0f4",
   "metadata": {},
   "source": [
    "#### Track the operation in LangSmith\n",
    "* [Open LangSmith here](smith.langchain.com)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2f3082-144a-4c48-bd93-ad885753b178",
   "metadata": {},
   "source": [
    "## Basic Multiagent App"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34abec9-3a35-4232-8fb9-a0ae86373776",
   "metadata": {},
   "source": [
    "If you are using the pre-loaded poetry shell, you do not need to install the following packages because they are already pre-loaded for you:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44a7fbb9-930c-4ea3-8ab0-f46261ee4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langgraph langchain-openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0464d757-1da0-4090-a148-f2612d0f3b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4fb3dae-c014-453c-abb7-0585b725482a",
   "metadata": {},
   "source": [
    "The previous command adds `beautifulsoup4`, a library for parsing HTML and XML documents, widely used for web scraping."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fb5861-8eb9-41c2-b8a0-76c0fbac31e4",
   "metadata": {},
   "source": [
    "## Add the Tavily API key in your .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fbec09c-4950-4bbb-9e17-e1621f668a5a",
   "metadata": {},
   "source": [
    "To get a Tavily API key, you can follow these simple steps:\n",
    "\n",
    "1. **Sign Up or Log In:** \n",
    "   - Visit the Tavily website.\n",
    "   - If you don't have an account, sign up by providing your details. If you already have an account, just log in.\n",
    "\n",
    "2. **Navigate to API Section:**\n",
    "   - Once logged in, find the section or menu item that mentions \"API\" or \"Developer Tools.\"\n",
    "   - This is usually in your account settings or a dedicated \"API\" page.\n",
    "\n",
    "3. **Create a New API Key:**\n",
    "   - Look for an option like \"Generate API Key\" or \"Create New Key.\"\n",
    "   - Click on it, and the system will generate an API key for you.\n",
    "\n",
    "4. **Copy the API Key:**\n",
    "   - Once the key is generated, it will be displayed on the screen.\n",
    "   - Copy it carefully and store it securely. You’ll need this key to access Tavily's API.\n",
    "\n",
    "5. **Use the API Key:**\n",
    "   - Use this key in your application or service to authenticate and interact with Tavily's API.\n",
    "\n",
    "That's it! You now have your Tavily API key and can start using it for your projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd33dde1-2682-48e9-a855-9053033d1bb5",
   "metadata": {},
   "source": [
    "* Add your Tavily API key in your .env file:\n",
    "\n",
    "TAVILY_API_KEY=yourkey"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af719a0-7184-47e0-9cc9-7f0dac7f797d",
   "metadata": {},
   "source": [
    "## Import the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c06e5584-b963-43ff-b8ce-428f724d0dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install typing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644fc82a-9818-48fc-ae02-d3de0c12892d",
   "metadata": {},
   "source": [
    "## Initial imports\n",
    "From now on we will comment the code out so it will not be executed in the notebook. In the following steps you will learn how to execute the code in the code editor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c4a69baf-fe80-46c2-ac4a-e707b26c48df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import functools\n",
    "# import operator\n",
    "# import requests\n",
    "# import os\n",
    "# from dotenv import load_dotenv\n",
    "# from bs4 import BeautifulSoup\n",
    "# from langchain.agents import AgentExecutor, create_openai_tools_agent\n",
    "# from langchain_core.messages import HumanMessage, BaseMessage\n",
    "# from langchain.output_parsers.openai_functions import JsonOutputFunctionsParser\n",
    "# from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "# from langgraph.graph import StateGraph, END\n",
    "# from langchain.tools import tool\n",
    "# from langchain_openai import ChatOpenAI\n",
    "\n",
    "# from typing import TypedDict, Annotated, Sequence\n",
    "\n",
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "# load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6446fef7-d6ae-4e47-9599-9691c81fc476",
   "metadata": {},
   "source": [
    "## Define the tools to use\n",
    "* Online searching with Tavily\n",
    "* HTML parsing with BeautifulSoup\n",
    "* return_direct=False\n",
    "    * Meaning: this tool will be returning results privately to the agent, not publicly to the app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87582c61-e32c-480c-b8a8-eb03a03a1ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# @tool(\"process_search_tool\", return_direct=False)\n",
    "# def process_search_tool(url: str) -> str:\n",
    "#     \"\"\"Used to process content found on the internet.\"\"\"\n",
    "#     response = requests.get(url=url)\n",
    "#     soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "#     return soup.get_text()\n",
    "\n",
    "# tools = [TavilySearchResults(max_results=1), process_search_tool]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8cff04-8596-4f8f-99b4-d140c9e6e631",
   "metadata": {},
   "source": [
    "* Important note: for demo and cost purposes, we have set the max_results of the online search with Tavily to only 1. This indeed will limit the quality of the online search since our online search agent will only study one search result instead of comparing several results.\n",
    "* When you work in a professional app, set the max_results to a higher number but be careful with the cost implications."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc20b97-05af-4541-8762-63b389e0ed33",
   "metadata": {},
   "source": [
    "## Define the function to create new agents\n",
    "* Arguments: llm, tool list, system prompt.\n",
    "* OpenAI tools agent.\n",
    "* Output: AgentExecutor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "796742c0-20e8-4db3-b2a8-1117150664c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_new_agent(llm: ChatOpenAI,\n",
    "#                   tools: list,\n",
    "#                   system_prompt: str) -> AgentExecutor:\n",
    "#     prompt = ChatPromptTemplate.from_messages([\n",
    "#         (\"system\", system_prompt),\n",
    "#         MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#         MessagesPlaceholder(variable_name=\"agent_scratchpad\")\n",
    "#     ])\n",
    "\n",
    "#     agent = create_openai_tools_agent(llm, tools, prompt)\n",
    "#     executor = AgentExecutor(agent=agent, tools=tools)\n",
    "#     return executor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1e66aa-adc0-4a3c-849a-a658c3db2877",
   "metadata": {},
   "source": [
    "This previous function is designed to set up and return an agent that can perform tasks using OpenAI's language model and a set of tools. Here’s a breakdown of what each part does:\n",
    "\n",
    "1. **Function Definition (`create_new_agent`)**:\n",
    "   - It takes four parameters:\n",
    "     - `llm`: an instance of `ChatOpenAI`, which refers to the language model from OpenAI.\n",
    "     - `tools`: a list of tools that the agent can use.\n",
    "     - `system_prompt`: a string that provides an initial message or command for the agent.\n",
    "   - The function is expected to return an instance of `AgentExecutor`.\n",
    "\n",
    "2. **Creating a Prompt**:\n",
    "   - `prompt = ChatPromptTemplate.from_messages([...])`: This line constructs a prompt for the agent using a template. The prompt includes:\n",
    "     - A system message (`system_prompt`).\n",
    "     - Two placeholders for additional dynamic content, labeled `\"messages\"` and `\"agent_scratchpad\"`. These are used to insert messages that the agent receives during its operation and notes or data that the agent might need to keep track of, respectively.\n",
    "\n",
    "3. **Creating an Agent**:\n",
    "   - `agent = create_openai_tools_agent(llm, tools, prompt)`: This line initializes the agent using the language model (`llm`), the list of tools (`tools`), and the prompt created earlier. The function (`create_openai_tools_agent`) is designed to configure the agent with the necessary components to function properly.\n",
    "\n",
    "4. **Creating an Executor**:\n",
    "   - `executor = AgentExecutor(agent=agent, tools=tools)`: This creates an `AgentExecutor` object, which manages the execution of the agent's tasks. It is configured with the agent itself and the tools the agent can use.\n",
    "\n",
    "5. **Return the Executor**:\n",
    "   - `return executor`: The function finishes by returning the `executor` object, which is now ready to handle tasks according to the `system_prompt` and interact using the tools provided.\n",
    "\n",
    "In simple terms, this function sets up an agent with specific tools and a starting instruction, ready to perform tasks as instructed by further interactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde9ffef-27bd-421e-bf0f-4d2d0e1f5cfc",
   "metadata": {},
   "source": [
    "## Define the function to create a node in the multi-agent network\n",
    "* Nodes are like the way we locate each agent in the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a87355c-a70f-408b-b3a7-d229ef738426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def agent_node(state, agent, name):\n",
    "#     result = agent.invoke(state)\n",
    "#     return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d91f41-74bd-4624-b93b-c4ff4f887749",
   "metadata": {},
   "source": [
    "The previous code defines a function named `agent_node` that takes three parameters: `state`, `agent`, and `name`. Here's a breakdown of what each part of the function does:\n",
    "\n",
    "1. **Function Definition (`def agent_node(state, agent, name)`):** \n",
    "   - `def` begins the definition of a function.\n",
    "   - `agent_node` is the name of the function.\n",
    "   - `state`, `agent`, and `name` are the inputs to the function. These are called parameters. `state` represents the current state, `agent` is the agent, and `name` is the node name.\n",
    "\n",
    "2. **Action (`result = agent.invoke(state)`):**\n",
    "   - Inside the function, `agent.invoke(state)` is called. The agent is executed with the `state` and returns a result.\n",
    "   - The result of this action is stored in a variable called `result`. The `result` is expected to be a dictionary that includes at least one key named `output`.\n",
    "\n",
    "3. **Return Value (`return {\"messages\": [HumanMessage(content=result[\"output\"], name=name)]}`):**\n",
    "   - The function then creates and returns a dictionary with a single key `messages`.\n",
    "   - The value associated with this key is a list containing a single instance of `HumanMessage`.\n",
    "   - `HumanMessage` takes two arguments: `content` and `name`. Here, `content` is set to the value of `result[\"output\"]` (the output from the `agent.invoke(state)` method), and `name` is the name passed to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccb2bd2-887a-4637-a90d-eaf71ea91ea7",
   "metadata": {},
   "source": [
    "## Create a list with the names of the AI Agents we will create to replace our content marketing team"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a90e77d5-4228-4689-8dc1-377ef312b04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_marketing_team = [\"online_researcher\", \"blog_manager\", \"social_media_manager\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ece107-8e5b-4138-961b-5d7bc1fa90a4",
   "metadata": {},
   "source": [
    "## Define the system prompt\n",
    "* The system_prompt defines the role of the content marketing manager. The content marketing manager decides when an agent should intervene in the network cycle.\n",
    "* Each agent delivers a report to the content marketing manager when her task is finished, and then the content marketing manager decides what to do next, if another agent takes charge or if the cycle finishes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8831865b-56c0-4f8a-bfe5-4020773f270c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# system_prompt = (\n",
    "#     \"As a content marketing manager, your role is to oversee the insight between these\"\n",
    "#     \" workers: {content_marketing_team}. Based on the user's request,\"\n",
    "#     \" determine which worker should take the next action. Each worker is responsible for\"\n",
    "#     \" executing a specific task and reporting back thier findings and progress.\"\n",
    "#     \" Once all tasks are completed, indicate 'FINISH'.\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c171720-f4cf-4f5a-98a7-e9f52f605c8b",
   "metadata": {},
   "source": [
    "## Create the options list\n",
    "* This list presents all the options the content marketing manager can choose from: the list of agent names and the \"FINISH\" option to finish the cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc823df-cc52-4383-afde-249ebec100aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# options = [\"FINISH\"] + content_marketing_team"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38284643-d419-4d14-b502-afbddae1c02c",
   "metadata": {},
   "source": [
    "## Define the routeSchema function\n",
    "* This function determines how to select the next agent in charge in the next cycle stage, the next role.\n",
    "* As you can see, in the properties it includes the options list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "568f6934-c6bb-45ed-9580-631f5f2b7d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function_def = {\n",
    "#     \"name\": \"route\",\n",
    "#     \"description\": \"Select the next role.\",\n",
    "#     \"parameters\": {\n",
    "#         \"title\": \"routeSchema\",\n",
    "#         \"type\": \"object\",\n",
    "#         \"properties\": {\"next\": {\"title\": \"Next\", \"anyOf\": [{\"enum\": options}]}},\n",
    "#         \"required\": [\"next\"]\n",
    "#     }\n",
    "# }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bf9543-c3ee-46b7-bccc-4f05a38e88b5",
   "metadata": {},
   "source": [
    "The previous function described in the JSON object is named `route`, and its primary purpose is to select the next role based on a specific schema called `routeSchema`. Let us break down the various components to clarify what each part does:\n",
    "\n",
    "1. **Name**: The function is called `route`. The name is self explanatory: the function helps in determining a direction or making a decision in a sequence of actions.\n",
    "\n",
    "2. **Description**: The description \"Select the next role\" is also self explanatory: the function's main task is to determine and select what the next role should be in our workflow.\n",
    "\n",
    "3. **Parameters**: This function takes one parameter defined by the `routeSchema`. Here's how the schema is structured:\n",
    "   \n",
    "   - **title**: The title of the parameter is `routeSchema`.\n",
    "   - **type**: It's of type `object`, meaning this parameter should be a structured object with properties defined under it.\n",
    "   - **properties**:\n",
    "     - The key property is `next`. It has the title \"Next\", and its value can be one of several options. These options are referenced as `options`, which means that `next` can take on any value from the options list.\n",
    "   - **required**: The property `next` is required, meaning that for the function to operate, the `next` property must be provided in the object passed to the function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba8b2abc-7818-44e4-9ca7-a0f04a2997e5",
   "metadata": {},
   "source": [
    "## Define the content marketing manager's prompt\n",
    "* Includes the system prompt.\n",
    "* Asks what option to take next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "33b86cfe-5a48-4fae-a83c-f1c7894f45af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt = ChatPromptTemplate.from_messages([\n",
    "#     (\"system\", system_prompt),\n",
    "#     MessagesPlaceholder(variable_name=\"messages\"),\n",
    "#     (\"system\",\n",
    "#      \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\"),\n",
    "# ]).partial(options=str(options), content_marketing_team=\", \".join(content_marketing_team))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a313fbf5-f647-4429-81ff-72f8825717c7",
   "metadata": {},
   "source": [
    "The previous code is be constructing a prompt template for our chat-based application. Let's break down each part of the code for clarity:\n",
    "\n",
    "1. **Creating a Prompt Template**:\n",
    "   - `ChatPromptTemplate.from_messages([])`: This is a method used to create a new chat prompt template. It takes a list of messages as an argument, which defines the structure of the conversation that will be presented to the user.\n",
    "\n",
    "2. **Defining the Conversation**:\n",
    "   - Inside the list passed to `from_messages`, there are tuples and placeholders that represent different parts of a conversation:\n",
    "     - `(\"system\", system_prompt)`: This tuple represents a message from the \"system\" using the variable `system_prompt`.\n",
    "     - `MessagesPlaceholder(variable_name=\"messages\")`: This is a placeholder for user messages that will be dynamically filled based on the actual conversation. The placeholder is labeled with a variable name `\"messages\"`, indicating where messages from the user or other participants should be inserted in the template.\n",
    "     - `(\"system\", \"Given the conversation above, who should act next? Or should we FINISH? Select one of: {options}\")`: System message that prompts the user to decide the next step in the conversation, providing specific options that are dynamically determined.\n",
    "\n",
    "3. **Dynamic Content**:\n",
    "   - `.partial(options=str(options), content_marketing_team=\", \".join(content_marketing_team))`: This part of the code modifies the template to include specific dynamic content:\n",
    "     - `options=str(options)`: The placeholder `{options}` in the last system message is replaced with a string representation of the variable `options`, which contains different actions or choices the user can make.\n",
    "     - `content_marketing_team=\", \".join(content_marketing_team)`: the list `content_marketing_team` is converted to a comma-separated string."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8afb6aa-6bd5-4ccc-b86e-6cf7915d1be2",
   "metadata": {},
   "source": [
    "## Define the content marketing manager's chain\n",
    "* Use the content marketing manager's prompt\n",
    "* Use the routerSchema function\n",
    "* Parse the output as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52dd7919-1052-4d2a-8161-c5cb7e0610b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# content_marketing_manager_chain = (prompt | llm.bind_functions(\n",
    "#     functions=[function_def], function_call=\"route\") | JsonOutputFunctionsParser())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407ab820-e894-43a3-b805-73bea4b27c10",
   "metadata": {},
   "source": [
    "## Create the online_researcher agent\n",
    "Remember, the create_new_agent function only requires 3 arguments:\n",
    "* What LLM will the agent use.\n",
    "* The list of tools the agent can use. In this exercise all angents share the same tool list, but they can have differente tool lists.\n",
    "* What prompt defines the agent's role."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f8cabc20-42eb-46a5-9f38-8bab7bcbfa6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# online_researcher_agent = create_new_agent(\n",
    "#     llm,\n",
    "#     tools,\n",
    "#     \"\"\"Your primary role is to function as an intelligent online research assistant, adept at scouring \n",
    "#     the internet for the latest and most relevant trending stories across various sectors like politics, technology, \n",
    "#     health, culture, and global events. You possess the capability to access a wide range of online news sources, \n",
    "#     blogs, and social media platforms to gather real-time information.\"\"\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91014a28-6e8a-424d-9fb1-1c4112041ea2",
   "metadata": {},
   "source": [
    "## Define the node where we can locate the previous agent\n",
    "* Using functools, we basically clone the agent_node function and add online_researcher_agent as argument and giving the node the name of \"online_researcher\". See how functions.partial works below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2edc7866-f39e-450f-b74f-34d3ed875517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# online_researcher_node = functools.partial(\n",
    "#     agent_node, agent=online_researcher_agent, name=\"online_researcher\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b78121e-afe1-4903-99ce-4bbd88ad0c24",
   "metadata": {},
   "source": [
    "#### What does functools.partial do?\n",
    "The `functools` module is part of the Python standard library and **doesn't need to be installed separately.**\n",
    "\n",
    "`functools` provides tools that help you modify and manage functions easily. Here’s a simplified explanation of some of its main features:\n",
    "\n",
    "1. **`partial`**: Imagine you have a recipe that you always cook with a slight variation. Instead of rewriting the recipe each time, you can write down the common steps and just specify the variation when needed. `partial` helps you create a simplified version of a function by pre-setting some arguments.\n",
    "\n",
    "2. **`lru_cache`**: This is like having a small notebook where you write down solutions to problems you've already solved. The next time you face the same problem, instead of solving it again, you just look at your notebook. This saves time, especially for complex problems.\n",
    "\n",
    "3. **`reduce`**: Suppose you have a list of numbers and you want to combine them into one number, maybe by adding them up. `reduce` takes a function (like addition) and a list, applies the function to combine the items of the list into a single result.\n",
    "\n",
    "4. **`total_ordering`**: If you have a class representing people with just their ages and you want to easily compare who is older or younger, you usually need to write several methods to compare them. With `total_ordering`, you just write one comparison method, and it figures out the rest for you.\n",
    "\n",
    "5. **`singledispatch`**: This lets you write a general function that can behave differently depending on what type of thing it is dealing with. For example, you might have a function that needs to handle both numbers and strings differently with just one function definition.\n",
    "\n",
    "6. **`cmp_to_key`**: Some tools in Python sort objects but need a special rule for how to rank them. `cmp_to_key` converts an old-style comparison function (which tells you which of two values is larger) into a key function that the sorting tool can use.\n",
    "\n",
    "Overall, `functools` helps make functions more versatile and easier to manage in your programs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adecd38-b208-4629-8842-a06df95250ac",
   "metadata": {},
   "source": [
    "## Repeat the previous two steps to create the other 2 agents with their corresponding nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8c6ddb0d-0c7e-4d46-b707-591d1cba2c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# blog_manager_agent = create_new_agent(\n",
    "#     llm, tools,\n",
    "#     \"\"\"You are a Blog Manager. The role of a Blog Manager encompasses several critical responsibilities aimed at transforming initial drafts into polished, SEO-optimized blog articles that engage and grow an audience. Starting with drafts provided by online researchers, the Blog Manager must thoroughly understand the content, ensuring it aligns with the blog's tone, target audience, and thematic goals. Key responsibilities include:\n",
    "\n",
    "# 1. Content Enhancement: Elevate the draft's quality by improving clarity, flow, and engagement. This involves refining the narrative, adding compelling headers, and ensuring the article is reader-friendly and informative.\n",
    "\n",
    "# 2. SEO Optimization: Implement best practices for search engine optimization. This includes keyword research and integration, optimizing meta descriptions, and ensuring URL structures and heading tags enhance visibility in search engine results.\n",
    "\n",
    "# 3. Compliance and Best Practices: Ensure the content adheres to legal and ethical standards, including copyright laws and truth in advertising. The Blog Manager must also keep up with evolving SEO strategies and blogging trends to maintain and enhance content effectiveness.\n",
    "\n",
    "# 4. Editorial Oversight: Work closely with writers and contributors to maintain a consistent voice and quality across all blog posts. This may also involve managing a content calendar, scheduling posts for optimal engagement, and coordinating with marketing teams to support promotional activities.\n",
    "\n",
    "# 5. Analytics and Feedback Integration: Regularly review performance metrics to understand audience engagement and preferences. Use this data to refine future content and optimize overall blog strategy.\n",
    "\n",
    "# In summary, the Blog Manager plays a pivotal role in bridging initial research and the final publication by enhancing content quality, ensuring SEO compatibility, and aligning with the strategic objectives of the blog. This position requires a blend of creative, technical, and analytical skills to successfully manage and grow the blog's presence online.\"\"\")\n",
    "\n",
    "\n",
    "# blog_manager_node = functools.partial(\n",
    "#     agent_node, agent=blog_manager_agent, name=\"blog_manager\")\n",
    "\n",
    "\n",
    "# social_media_manager_agent = create_new_agent(\n",
    "#     llm, tools,\n",
    "#     \"\"\"You are a Social Media Manager. The role of a Social Media Manager, particularly for managing Twitter content, involves transforming research drafts into concise, engaging tweets that resonate with the audience and adhere to platform best practices. Upon receiving a draft from an online researcher, the Social Media Manager is tasked with several critical functions:\n",
    "\n",
    "# 1. Content Condensation: Distill the core message of the draft into a tweet, which typically allows for only 280 characters. This requires a sharp focus on brevity while maintaining the essence and impact of the message.\n",
    "\n",
    "# 2. Engagement Optimization: Craft tweets to maximize engagement. This includes the strategic use of compelling language, relevant hashtags, and timely topics that resonate with the target audience.\n",
    "\n",
    "# 3. Compliance and Best Practices: Ensure that the tweets follow Twitter’s guidelines and best practices, including the appropriate use of mentions, hashtags, and links. Also, adhere to ethical standards, avoiding misinformation and respecting copyright norms.\n",
    "\n",
    "# In summary, the Social Media Manager's role is crucial in leveraging Twitter to disseminate information effectively, engage with followers, and build the brand’s presence online. This position combines creative communication skills with strategic planning and analysis to optimize social media impact.\"\"\")\n",
    "\n",
    "# social_media_manager_node = functools.partial(\n",
    "#     agent_node, agent=social_media_manager_agent, name=\"social_media_manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2952a911-8a9e-4cb2-aab1-83e765b4a32d",
   "metadata": {},
   "source": [
    "## Define Individual Agent Memory: the AgentState class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4e8e7dfe-4a91-412f-9046-0a827dc4e76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class AgentState(TypedDict):\n",
    "#     messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "#     next: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e983c34-3616-413c-b48d-ec720e1ecbc3",
   "metadata": {},
   "source": [
    "The previous code defines a Python class called `AgentState` using a feature called `TypedDict` from the `typing` module. Here’s what each part does in simple terms:\n",
    "\n",
    "1. **`TypedDict`**: This is used to create a dictionary where you can specify the type of data each key should hold. It's a way to make sure your dictionaries are more predictable by ensuring each key has a specific type of value.\n",
    "\n",
    "2. **`AgentState`**: This is the name of the dictionary type being defined. You can think of `AgentState` as a blueprint for creating dictionaries that always have the same structure.\n",
    "\n",
    "3. **`messages`**: This is one of the keys in the `AgentState` dictionary. It is expected to hold a sequence (like a list or a tuple) of items, each of which is an instance of `BaseMessage`. `BaseMessage` is a Base class in LangChain for all types of messages in a conversation. It includes properties like `content`, `name`, and `additional_kwargs`. It also includes methods like `toDict()` and `_getType()`.\n",
    "\n",
    "   - **`Annotated[Sequence[BaseMessage], operator.add]`**: Here, `Annotated` is used to add additional information to the type hint. This extra information is `operator.add`, suggesting that the values in the `messages` sequence might be combined using the addition operation, indicating that messages can be concatenated or aggregated. The `operator` module in Python provides a set of functions corresponding to the intrinsic operators of Python. For example, instead of using + for addition, operator.add(x, y) can be used. \n",
    "\n",
    "4. **`next`**: This is another key in the `AgentState` dictionary. It holds a value of type `str`, which means it's expected to be a string. This could be used to indicate the next action, state, or identifier in a process or workflow involving an \"agent.\"\n",
    "\n",
    "In summary, the `AgentState` class defines a template for creating dictionaries that keep track of an agent's messages and its next state or action. Each `AgentState` dictionary will have a list of `messages` that are instances of `BaseMessage` and a `next` value that is a string. The use of `Annotated` with `operator.add` might imply some special handling or processing of the messages that isn't standard in typical type hints."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f67e804-ceff-4f42-8689-310f084f4903",
   "metadata": {},
   "source": [
    "## Let's now create the Workflow of the Agent Network, what in LangGraph is called a Graph or a Stateful Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b70fc1-c7a2-4547-9d81-591642e3eec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow = StateGraph(AgentState)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ccdb09-45dd-482d-896b-3f0ed1de5822",
   "metadata": {},
   "source": [
    "## Let's now add the nodes of the Workflow (also called the nodes of the Graph)\n",
    "* See that the action of the content_marketing_manager's node is the content_marketing_manager_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be6a4f2f-7934-4d3d-b540-f3ccfad64ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# workflow.add_node(key=\"content_marketing_manager\", action=content_marketing_manager_chain)\n",
    "# workflow.add_node(key=\"online_researcher\", action=online_researcher_node)\n",
    "# workflow.add_node(key=\"blog_manager\", action=blog_manager_node)\n",
    "# workflow.add_node(key=\"social_media_manager\", action=social_media_manager_node)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f433b7b-150f-4303-a28a-3507ab378462",
   "metadata": {},
   "source": [
    "## And now we will add the connections among the nodes, what in LangGraph are called the \"edges\"\n",
    "* These are the connections among the agents and the content marketing manager.\n",
    "* See that each edge starts in the agent and ends up in the content marketing manager. This is like saying: \"each agent is going to report what she has been working on to the content marketing manager\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e2ec8e9a-ab42-44eb-9190-24d26af4b652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for member in content_marketing_team:\n",
    "#     workflow.add_edge(start_key=member, end_key=\"content_marketing_manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e72c391-b815-464c-a3da-b5ba601efe85",
   "metadata": {},
   "source": [
    "## Now let's add a Conditional Map\n",
    "* If task is FINISHED, the content marketing manager won't send a new task to the agent.\n",
    "* Else, the content marketing manager will keep on sending task to the agent untill done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2c7fbd65-7392-491e-ae9c-7a09ff5c14aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# conditional_map = {k: k for k in content_marketing_team}\n",
    "\n",
    "# conditional_map['FINISH'] = END\n",
    "\n",
    "# workflow.add_conditional_edges(\n",
    "#     \"content_marketing_manager\", lambda x: x[\"next\"], conditional_map)\n",
    "\n",
    "# workflow.set_entry_point(\"content_marketing_manager\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38ee351-a291-47d2-be85-1188b1c30386",
   "metadata": {},
   "source": [
    "Here's a breakdown of each part of the code and what it does in simple terms:\n",
    "\n",
    "1. **`conditional_map = {k: k for k in content_marketing_team}`**:\n",
    "   - This line creates a dictionary named `conditional_map` where each key and its corresponding value are the same. The keys (and values) are taken from the list `content_marketing_team`.\n",
    "\n",
    "2. **`conditional_map['FINISH'] = END`**:\n",
    "   - Here, the dictionary `conditional_map` is updated to include a new key `'FINISH'` with a corresponding value `END`. See that we imported `END` from langgraph.graph in the top section of multiagent.py\n",
    "\n",
    "3. **`workflow.add_conditional_edges(\"content_marketing_manager\", lambda x: x[\"next\"], conditional_map)`**:\n",
    "   - This line adds conditional edges to a `workflow` object. The first argument `\"content_marketing_manager\"` is a node in the workflow.\n",
    "   - The second argument is a lambda function `lambda x: x[\"next\"]`. This function is used to determine the next step in the workflow based on the current state's `\"next\"` attribute. Essentially, it looks at the current context or state (`x`), retrieves what is specified by `\"next\"`, and uses this to decide the next action or node in the workflow.\n",
    "   - The third argument, `conditional_map`, provides a mapping from possible values of `x[\"next\"]` to what actually should happen next in the workflow. This enables dynamic decision-making within the workflow based on the current state.\n",
    "\n",
    "4. **`workflow.set_entry_point(\"content_marketing_manager\")`**:\n",
    "   - Finally, this line sets the entry point of the workflow to `\"content_marketing_manager\"`. This means that `\"content_marketing_manager\"` is the starting point or initial state from which the workflow begins execution.\n",
    "\n",
    "In essence, this code is configuring a workflow where execution starts at the `\"content_marketing_manager\"` node, uses a dictionary (`conditional_map`) to map potential next steps based on the current context, and dynamically determines the flow based on the current state's `\"next\"` value."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cac4aaf1-40b9-43c9-a031-fa1b85eb7409",
   "metadata": {},
   "source": [
    "## Our final step, let's initialize the agent network (often called graph in LangGraph) and let's ask it to do some work for us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5953d1d2-6a89-4758-a374-c55dc17a0b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# multiagent = workflow.compile()\n",
    "\n",
    "# for s in multiagent.stream(\n",
    "#     {\n",
    "#         \"messages\": [\n",
    "#             HumanMessage(\n",
    "#                 content=\"\"\"Write me a report on Agentic Behavior. After the research on Agentic Behavior,pass the findings to the blog manager to generate the final blog article. Once done, pass it to the social media manager to write a tweet on the subject.\"\"\"\n",
    "#             )\n",
    "#         ],\n",
    "#     },\n",
    "#     # Maximum number of steps to take in the graph\n",
    "#     {\"recursion_limit\": 150}\n",
    "# ):\n",
    "#     if not \"__end__\" in s:\n",
    "#         print(s, end=\"\\n\\n-----------------\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6126c24-7ea9-4f0d-b2d5-764879813572",
   "metadata": {},
   "source": [
    "## Before running the app\n",
    "* Be careful, because running Multi-Agent apps like this with chatGPT-4 is going to be more expensive than running traditional apps. Pay attention to the total cost in LangSmith. For us it was around $0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c66917-5d44-4ac3-a7b0-2ccae3281a39",
   "metadata": {},
   "source": [
    "## How to execute the code from Visual Studio Code\n",
    "* In Visual Studio Code, see the file 001-basic-multiagent.py\n",
    "* In terminal, make sure you are in the directory of the file and run:\n",
    "    * python 001-basic-multiagent.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af04681-b7aa-4978-9350-66943bfa7ea8",
   "metadata": {},
   "source": [
    "## You can then see workflow steps displayed in the terminal\n",
    "* The content marketing manager asks the online researcher to research online about the article topic and write the first draft.\n",
    "* The online researcher delivers the draft.\n",
    "* When the content marketing manager is satisfied with the work of the online researcher, the content marketing manager asks the blog manager to fine tune the draft.\n",
    "* The blog manager delivers the final article.\n",
    "* When the content marketing manager is satisfied with the work of the blog manager, the content marketing manager asks the social media manager to write a tweet about the article.\n",
    "* The social media manager delivers the tweet.\n",
    "* When the content marketing manager is satisfied with the work of the social media manager, the content marketing manager ends the workflow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15ddf9d-876f-4c4b-a997-cb5ac1af5202",
   "metadata": {},
   "source": [
    "## Take a look at LangSmith\n",
    "* See that the project takes a lot of tokens.\n",
    "* See that each agent is monitored.\n",
    "* Click on each agent and see input and output.\n",
    "* See how the online researcher agent is using Tavily for online searching.\n",
    "* See the output of the content marketing manager in the last step (\"FINISH\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424efd2-b51f-4938-85a9-5018ae49bb79",
   "metadata": {},
   "source": [
    "## One important caveat: Multi-Agent Networks take time to deliver the final solution, so you will have to be patient.\n",
    "* Multi-Agent Networks, also called LLM Apps with Agentic Behavior or Multi-Agent LLM Apps take time, but their results are often better than the ones got from Non-Agentic LLM Apps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80e7955d-8c0d-4e7d-8a80-1dda360e9d53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
